{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses tika to parse text from the table of contents pdfs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tika\n",
    "import os\n",
    "import re\n",
    "\n",
    "from tika import parser "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table of conents have been cropped and had their title pages removed etc. in the 'Split' folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "basefolder = r\"C:\\Users\\aspit\\OneDrive\\SEAMs\\NLP\"\n",
    "os.listdir(basefolder)\n",
    "\n",
    "fps = os.walk(os.path.join(basefolder, 'Split'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readpdfRaw(filelocation):\n",
    "    \"\"\"Module takes path to text file location and returns a list of sentences from doc using Tika\n",
    "    Args:\n",
    "        filelocation: location of the document file\n",
    "\n",
    "    Returns:\n",
    "        doctext: text from the document\n",
    "    \"\"\"\n",
    "    print(\"Parsing file with Tika...\")\n",
    "    parsed = parser.from_file(filelocation)\n",
    "    try:\n",
    "        doctext = parsed[\"content\"]\n",
    "        docmeta = parsed[\"metadata\"]\n",
    "\n",
    "    except Exception as E:\n",
    "        print(E, \"Document has no text\")\n",
    "        doctext = ''\n",
    "    return doctext, docmeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n",
      "Parsing file with Tika...\n"
     ]
    }
   ],
   "source": [
    "d = {}\n",
    "\n",
    "for path, direc, filenames in fps:\n",
    "    for filename in filenames:\n",
    "        if '.pdf' in filename:\n",
    "#             print(filename)\n",
    "            doc = os.path.join(path,filename) \n",
    "            doctext, metadata = readpdfRaw(doc)\n",
    "            \n",
    "            m = re.search('SEAM_(\\d+).pdf',filename)\n",
    "            num = int(m.groups()[0])\n",
    "            \n",
    "#             print(num)\n",
    "            \n",
    "            d[num] = doctext\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing\n",
    "\n",
    "Remove stopwords and make all lowercase.\n",
    "Then process the words based on the frequency in which they appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = set()\n",
    "\n",
    "text_corpus = []\n",
    "\n",
    "for i in range(len(d)):\n",
    "    text_corpus.append(d[i+1])\n",
    "\n",
    "stoplist.update({'a','b'})\n",
    "\n",
    "stoplist\n",
    "\n",
    "# Create a set of frequent words\n",
    "stoplist = set('for a of the and to in . ,'.split(' '))\n",
    "stoplist.update({'xiii', 'contents','preface','list','contributors'})\n",
    "stoplist.update({'norman','weinstein','richard','william','charles','james','carter','george','rosa','sutton'})\n",
    "# Lowercase each document, split it by white space and filter out stopwords\n",
    "\n",
    "texts = []\n",
    "\n",
    "for document in text_corpus:\n",
    "    words = []\n",
    "    for word in document.lower().split():\n",
    "        if (word not in stoplist) and (len(word)>3):\n",
    "            words.append(word)\n",
    "    \n",
    "    texts.append(words)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "#          for document in text_corpus]\n",
    "\n",
    "# Count word frequencies\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "# Only keep words that appear more than once\n",
    "processed_corpus = [[token for token in text if frequency[token] > 10] for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(processed_corpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
