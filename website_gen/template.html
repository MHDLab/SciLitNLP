---
layout: null
title: {{ long_name }}
---
<html>
<head>
    <title>Topic Modeling Report ('{{ regex }}')</title>
    <meta charset="utf-8">
    <link rel="stylesheet" href="main.css">
    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500&display=swap" rel="stylesheet">
</head>
<body>

<header>
  <h1>
    Topic Modeling Report for '{{ long_name }}'
  </h1>
</header>

<section class="proj">
<p>
This page is a programatically generated report of the results of topic modeling algorithms on a collection of scientific literature. Expand the sections below for more information. The code can be found on <a href=https://github.com/MHDLab/SciLitNLP>GitHub</a>. You can find other topic modeling reports <a href=https://mhdlab.github.io/nlp_reports>here</a>.
</p>

<button type="button" class="collapsible"> <u>Dataset:</u> <b>{{ n_papers }}</b> papers that were found in the Semantic Scholar Open Research Corpus containing the regular expression <b>'{{ regex }}'</b> in the abstract or title</button>
    <div class="extended">
        <p>
            The dataset used in this work is the <a href=https://api.semanticscholar.org/corpus>Semantic Scholar Open Research Corpus</a>.
            The full dataset includes the paper metadata (title, abstract, citation info, etc. ) for over 25 million papers stored locally in a ~100 Gb sqlite database. Topic modeling is performed on a subset of this data that is obtained by finding papers that contain the regular expression <b>'{{ regex }}'</b> in the title or abstract.
            
        </p>

        <center>
          <figure>
            <img src="img/full_corpus_pub_annual.png" width = 500></img>
            <img src="img/search_term_pub_percent.png" width = 500></img>
            <figcaption style="text-align: center;font-style: italic;">Left: The number of all annual publications in the left) full Semantic Scholar Open Research Corpus database and right) The percentage of papers containing regular expression <b>'{{ regex }}'</b> in the title or abstract.</figcaption>
          </figure>
        </center>
        <p>

            Note: the 25 million papers mentioned above is a temporarily downselected version of the entire semantic scholar dataset. The dataset includes topic tags created by the now-defunct Microsoft Academic(MA), for the moment, for the inital phase of development we have reduced the database size by downselecting to papers containing the following MA topics:
        'Chemistry',
        'Computer Science',
        'Engineering',
        'Physics',
        'Materials Science',
        'Mathematics',
        'Economics',
        'Geology',
        'Environmental Science'. For more information see <a href=https://github.com/allenai/s2orc>here</a>.
        </p>
    </div>

<button type="button" class="collapsible"> <u>Topic Modeling:</u> a <b>{{ model_type }}</b> topic model created with <b>{{ n_topics }}</b> topics </button>
    <div class="extended">

        <p>
            Topic modeling refers to machine learning algorithms that find collections of words that describe a corpus (collection of documents). 
            The topic modeling is performed with either a <a href=https://github.com/gregversteeg/corex_topic>Correlation Explanation (CorEx) topic model</a> or a <a href=https://radimrehurek.com/gensim/models/ldamodel.html>Gensim Latent Dirichlet Allocaiton (LDA)</a> topic model. 
        </p>

        <center>
          <figure>
            <img src="img/topic_modeling_schematic.png" width = 500></img>
            <figcaption style="text-align: center;font-style: italic;">A schematic of a general topic modeling agorithm where each word and document has some probability of being associated with a topic. One caveat is that for CorEx topic models, each word only belongs to one topic. </figcaption>
          </figure>
        </center>

        <p>
          Below is a plot of some different topics extracted from the corpus and their relative probabilities over time. The most probable words of the topic are shown above each figure. These words showcase the text processing that combines different variations on a word (i.e. strategy, strategic) into one root 'stem'. 
          The probability is calculated for each year by summing the given topic's probability over each paper, then normalizing so the sum of all topic probabilites for that year is 1.
        </p>
        <center>
          <figure>
            <img src="img/top_slopes_plot.png" width = 1500></img>
            <figcaption style="text-align: center;font-style: italic;"> The topics sorted by the largest positive slope in the last five years. i.e. trending</figcaption>
          </figure>
          <figure>
            <img src="img/neg_slopes_plot.png" width = 1500></img>
            <figcaption style="text-align: center;font-style: italic;"> The topics sorted by the largest negative slope in the last five years. </figcaption>
          </figure>
        </center>
    </div>
</section>



<section class="proj">

  <h2> Interactive Topic Model Plot  </h2>
  <p>The nodes of the network represent the topics of the topic model. Click them for more information. </p>

  <button type="button" class="collapsible"> Expand for plot description and instructions</button>
      <div class="extended">
        <p>
        Each node represents a topic and each edge between two topics represents the likelihood of the two topics appearing in an abstract together.
        The layout and scale of the axes is determined by the <a href=https://networkx.org/documentation/stable/reference/generated/networkx.drawing.layout.spring_layout.html>networkx spring_layout algorithm</a>. The algorithm tries to keep the <b>n</b> nodes <b>1/sqrt(n)</b> distance apart, which ends up determing the scale of the axes. This is not particularly informative so the axis tick marks are omitted.  
        <br>
        <br>
        <b>NODE COLOR:</b> community assigned by the <a href=https://python-louvain.readthedocs.io/en/latest>Louvain community detection algorithm</a>.<br>
        <b>NODE SIZE:</b> overall probability of the topic appearing in the analyzed collection of texts as a whole.<br>
        <b>NODE OPACITY:</b> probability of the topic appearing in the analyzed collection of texts over the past 5 years (opacity = 0.5 + 0.5*recent_probability).<br>
        <b>EDGE THICKNESS:</b> logarithmically scaled values of the <a href=https://aclanthology.org/W14-3112.pdf>topic covariance matrix</a>, related to how often those two topics show up together in a given paper<br>
        </p>
        <ul>
          <li>Click on a topic to view information about that topic including the papers with the highest probability of containing the selected topic (will appear to the right), and the topic probability trend (lower right) .</li>
          <li>Click in the blank area to reset the selection to nothing</li>
          <li>With one topic selected, select another connected node (pink lines) to view the papers and words with the highest probabilities in both topics. In this case the 'topic_prob' is the probability of the two topics for that paper multiplied. Note that the words in CorEx topic models belong to only one topic, so there is no implemented method of finding the words associated with both topics. </li>
        </ul>
        </p>
      </div>


  <embed type="text/html" src="topic_network.html" width=2000, height=2500> </embed>

</section>





    <script>
      var coll = document.getElementsByClassName("collapsible");
      var i;
      
      for (i = 0; i < coll.length; i++) {
        coll[i].addEventListener("click", function() {
          this.classList.toggle("active");
          var content = this.nextElementSibling;
          if (content.style.display === "block") {
            content.style.display = "none";
            console.log('hide');
          } else {
            content.style.display = "block";
            console.log('display');
          }
        });
      }
    </script>
</body>
</html>